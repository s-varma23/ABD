version: '3'

##### services #####
services:

  ### clients ###  
  #drill#
  drill:
    image: apache/drill:1.19.0
    hostname: drill
    command: /bin/bash
    tty: true
    ports:
    - "8047:8047"
    - "31010:31010"
    ulimits:
      memlock: -1
      nproc: 32768
      nofile: 100000
    volumes: 
      - ./datasets:/home/jovyan/datasets

  #jupyter#
  jupyter:
    image: ist769/jupyter_pyspark:20210924b 
    hostname: jupyter
    environment:
      - GRANT_SUDO=yes
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=SU2orange!       
    ports:
      - "8888:8888"
    volumes: 
      - ./work:/home/jovyan/work
      - ./datasets:/home/jovyan/datasets
    env_file:
      - ./hadoop-hive.env

  nuoadmin1:
    image: nuodb/nuodb-ce:latest
    command: nuoadmin
    hostname: nuoadmin1
    ports:
      - 8888:8888
    volumes:
      - nuoadmin-raft-1:/var/opt/nuodb
    environment:
      NUODB_DOMAIN_ENTRYPOINT: nuoadmin1

  test-sm-1:
    image: nuodb/nuodb-ce:latest
    command: nuodocker --api-server nuoadmin1:8888 start sm --db-name test --server-id nuoadmin1 --dba-user dba --dba-password goalie
    hostname: test-sm-1
    volumes:
      - test-arch-vol-1:/var/opt/nuodb


  test-te-1:
    image: nuodb/nuodb-ce:latest
    command: nuodocker --api-server nuoadmin1:8888 start te --db-name test --server-id nuoadmin1
    hostname: test-te-1



  #mongoexpress#
  mongoexpress:
    image: mongo-express:latest
    hostname: mongoexpress
    ports:
      - 8881:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: mongopw
      ME_CONFIG_MONGODB_URL: mongodb://admin:mongopw@mongo:27017/
    depends_on: 
      - mongo

  #rediscommander#
  rediscommander:
    image: rediscommander/redis-commander
    hostname: rediscommander
    environment: 
      REDIS_PORT: "6379"
      REDIS_HOST: "redis" 
    ports: 
      - 8882:8081
    depends_on: 
      - redis 


  ### database servers ###  
  #cassandra#
  cassandra:
    image: cassandra:3.11.11
    hostname: cassandra
    ports:
    - 9042:9042
    #- 9160:9160
    #- 7199:7199
    #- 8778:8778

    # environment:
    # - CASSANDRA_START_RPC=true
    # - CASSANDRA_SEEDS=cassandra
    # - CASSANDRA_CLUSTER_NAME=mtech_cluster
    ulimits:
      memlock: -1
      nproc: 32768
      nofile: 100000
    volumes:
      - cassandra-data:/var/lib/cassandra

  #elasticsearch#
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    hostname: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - xpack.security.enabled=false
#      - cluster.name=es-docker-cluster
#      - cluster.initial_master_nodes=es01
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300

  #kibana#
  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.0
    hostname: kibana
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD: SU2orange!
      SERVER_SSL_ENABLED: "false"
    depends_on:
      - elasticsearch

  #minio#
  minio:
    image: minio/minio:latest
    hostname: minio
    command: server /data --console-address ":9001"
    ports:
    - "9000:9000"
    - "9001:9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: SU2orange!
    volumes:
      - minio-data:/data 

  #mongo#
  mongo:
    image: mongo:6.0.4
    hostname: mongo
    ports:
      - 27017:27017
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: mongopw
    volumes:
      - mongo-data:/data/db 


  #mssql#
  mssql:
    #image: mcr.microsoft.com/azure-sql-edge:latest
    image: mcr.microsoft.com/mssql/server:2019-latest
    cap_add: [ 'SYS_PTRACE' ]
    hostname: mssql
    environment:
      - "ACCEPT_EULA=Y"
      - "SA_PASSWORD=SU2orange!"
      - "MSSQL_TELEMETRY_ENABLED=false"
    ports:
      - "1433:1433"
    volumes:
      - mssql-data:/var/opt/mssql

  # neo4j#
  neo4j:
    image: neo4j:4.4
    hostname: neo4j
    ports:
      - "7474:7474" #http
    #  - "7473:7473" #https
      - "7687:7687" #bolt
    environment:
      - "NEO4J_ACCEPT_LICENSE_AGREEMENT=yes"
      - "NEO4J_AUTH=none"
      - "NEO4J_dbms_memory_pagecache_size=1G"
      - "NEO4J_dbms_directories_plugins=/plugins"
      - "NEO4J_dbms_security_procedures_unrestricted=algo.*,apoc.*,gds.*"
    volumes:
      - neo4j-data:/data
      - ./neo4j-plugins:/plugins

  #redis#
  redis:
    image: redis:latest 
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data


  #hive/hadoop#
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    hostname: namenode
    volumes:
      - hdfs-namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hive
    env_file:
      - ./hadoop-hive.env
    ports:
      - "50070:50070"
      
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    hostname: datanode
    volumes:
      - hdfs-datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
      - namenode
    ports:
      - "50075:50075"

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    hostname: hive-server
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    volumes:
      - ./datasets:/datasets:ro
    depends_on:
      - hive-metastore
    ports:
      - "10000:10000"
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    hostname: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    depends_on:
      - hive-metastore-postgresql
    ports:
      - "9083:9083"
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    hostname: hive-metastore-postgresql
    volumes:
      - metastore-postgresql:/var/lib/postgresql/data
    depends_on:
      - datanode

  #kafka#
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  broker:
    image: confluentinc/cp-server:6.2.0
    hostname: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
  schema-registry:
    image: confluentinc/cp-schema-registry:6.2.0
    hostname: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  connect:
    image: cnfldemos/cp-server-connect-datagen:0.5.0-6.2.0
    hostname: connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-6.2.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
  control-center:
    image: confluentinc/cp-enterprise-control-center:6.2.0
    hostname: control-center
    depends_on:
      - broker
      - schema-registry
      - connect
      - ksqldb-server
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021
  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:6.2.0
    hostname: ksqldb-server
    depends_on:
      - broker
      - connect
    ports:
      - "8088:8088"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_BOOTSTRAP_SERVERS: "broker:29092"
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:6.2.0
    hostname: ksqldb-cli
    depends_on:
      - broker
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
  ksql-datagen:
    image: confluentinc/ksqldb-examples:6.2.0
    hostname: ksql-datagen
    depends_on:
      - ksqldb-server
      - broker
      - schema-registry
      - connect
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b broker:29092 1 40 && \
                       echo Waiting for Confluent Schema Registry to be ready... && \
                       cub sr-ready schema-registry 8081 40 && \
                       echo Waiting a few seconds for topic creation to finish... && \
                       sleep 11 && \
                       tail -f /dev/null'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      STREAMS_BOOTSTRAP_SERVERS: broker:29092
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
      STREAMS_SCHEMA_REGISTRY_PORT: 8081
  rest-proxy:
    image: confluentinc/cp-kafka-rest:6.2.0
    depends_on:
      - broker
      - schema-registry
    ports:
      - 8082:8082
    hostname: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'

  ### applications ### 
  #mongoapp#
  mongoapp:
    image: mafudge/mongoapp:20211116a
    ports:
      - 5081:5000
    environment:
      - "MONGODB_URI=mongodb://admin:mongopw@mongo:27017/"
    depends_on: 
      - mongo

  #retwis# 
  retwis:
    image: mafudge/retwis:20211116a
    ports: 
      - 5082:80
    depends_on: 
      - redis      
    


##### volumes #####
volumes:
  cassandra-data:
    driver: local
  elasticsearch-data:
    driver: local
  minio-data:
    driver: local
  mongo-data:
    driver: local
  mssql-data:
    driver: local
  neo4j-data:
    driver: local
  redis-data:
    driver: local
  metastore-postgresql:
    driver: local
  hdfs-datanode:
    driver: local
  hdfs-namenode:
    driver: local
  nuoadmin-raft-1:
    driver: local
  test-arch-vol-1:
    driver: local
  


##### networks #####
networks:
  default:
    name: local
    driver: bridge
    ipam:
      config:
        - subnet: 10.10.10.0/24
          gateway: 10.10.10.1
